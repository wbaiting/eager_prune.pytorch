{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.util import accuracy, AverageMeter, DataPrefetcher, get_logger, seed_torch, warm_up_lr, get_config_file\n",
    "from utils.select_model import get_network\n",
    "from utils.select_dataset import get_dataset\n",
    "from eager_pruner import EagerPruner\n",
    "from parsers import parse_args\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "from thop import profile, clever_format\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, scheduler, pruner, epoch, logger,\n",
    "          args):\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    iters = len(train_loader)\n",
    "    prefetcher = DataPrefetcher(train_loader)\n",
    "    inputs, labels = prefetcher.next()\n",
    "    iter_index = 1\n",
    "    while inputs is not None:\n",
    "        if epoch <= args.warmup_epoch:\n",
    "            warm_up_lr(optimizer, epoch, iter_index, args.warmup_epoch, iters, args.lr)\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss = loss / args.accumulation_steps\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        if iter_index % args.accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        #剪枝\n",
    "        if args.use_prune:\n",
    "            pruner.set_zero_by_mask()\n",
    "            if pruner.finish_flag == False:\n",
    "                if pruner.loss_increase_check(loss.item()):\n",
    "                    if pruner.roll_back_check():\n",
    "                        logger.info(\n",
    "                        f\"train: epoch {epoch:0>3d}, iter [{iter_index:0>4d}, {iters:0>4d}], roll back\")\n",
    "                        pruner.roll_back(epoch - 1, iter_index - 1)\n",
    "                        if pruner.pruning_termination_check():\n",
    "                            pruner.finish_flag = True\n",
    "                            logger.info(\n",
    "                                    f\"train: epoch {epoch:0>3d}, iter [{iter_index:0>4d}, {iters:0>4d}],{pruner.curr_fail_times:d} times failed, prune finished \")\n",
    "                        else:\n",
    "                            pruner.prune_num  = int(pruner.prune_num / 2)\n",
    "                            if pruner.prune_num == 0:\n",
    "                                pruner.finish_flag = True\n",
    "                                logger.info(\n",
    "                                f\"train: epoch {epoch:0>3d}, iter [{iter_index:0>4d}, {iters:0>4d}], prune finished\")\n",
    "                if pruner.pruning_check(epoch - 1, iter_index - 1):\n",
    "                    logger.info(\n",
    "                    f\"train: epoch {epoch:0>3d}, iter [{iter_index:0>4d}, {iters:0>4d}], begin prune\")\n",
    "                    pruner.backup_and_prune(epoch - 1, iter_index - 1)\n",
    "                    overall_rate, layers_rate = pruner.get_prune_rate()\n",
    "                    logger.info(\n",
    "                    f\"train: epoch {epoch:0>3d}, iter [{iter_index:0>4d}, {iters:0>4d}],finish prune, prune_num {pruner.prune_num:d},prune_rate {pruner.current_num/pruner.all_weights_num}，max_smoothed_loss {pruner.last_prune_loss_max:f}\")\n",
    "                    for i, rate in enumerate(layers_rate):\n",
    "                        logger.info(f\"layer {i:0>4d}, rate {rate:.3f}\")\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(outputs, labels, topk=(1, 5))\n",
    "        top1.update(acc1.item(), inputs.size(0))\n",
    "        top5.update(acc5.item(), inputs.size(0))\n",
    "        losses.update(loss.item(), inputs.size(0))\n",
    "\n",
    "        inputs, labels = prefetcher.next()\n",
    "\n",
    "        if iter_index % args.print_interval == 0:\n",
    "            logger.info(\n",
    "                f\"train: epoch {epoch:0>3d}, iter [{iter_index:0>4d}, {iters:0>4d}], lr: {optimizer.param_groups[0]['lr']:.6f}, top1 acc: {acc1.item():.2f}%, top5 acc: {acc5.item():.2f}%, loss_total: {loss.item():.2f}\"\n",
    "            )\n",
    "\n",
    "        iter_index += 1\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    return top1.avg, top5.avg, losses.avg\n",
    "\n",
    "\n",
    "def validate(val_loader, model, args):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for inputs, labels in val_loader:\n",
    "            data_time.update(time.time() - end)\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            acc1, acc5 = accuracy(outputs, labels, topk=(1, 5))\n",
    "            top1.update(acc1.item(), inputs.size(0))\n",
    "            top5.update(acc5.item(), inputs.size(0))\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "    throughput = 1.0 / (batch_time.avg / inputs.size(0))\n",
    "\n",
    "    return top1.avg, top5.avg, throughput\n",
    "\n",
    "\n",
    "def main(logger, args):\n",
    "    if not torch.cuda.is_available():\n",
    "        raise Exception(\"need gpu to train network!\")\n",
    "\n",
    "    if args.seed is not None:\n",
    "        seed_torch(args.seed)\n",
    "\n",
    "    logger.info(f'use {args.gpus} gpu')\n",
    "    logger.info(f\"args: {args}\")\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    cudnn.enabled = True\n",
    "    start_time = time.time()\n",
    "\n",
    "    # dataset and dataloader\n",
    "    logger.info('start loading data')\n",
    "    train_dataset, val_dataset = get_dataset(args)\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=args.batch_size,\n",
    "                              shuffle=True,\n",
    "                              pin_memory=True,\n",
    "                              num_workers=args.num_workers)\n",
    "    val_loader = DataLoader(val_dataset,\n",
    "                            batch_size=args.batch_size,\n",
    "                            shuffle=False,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=args.num_workers)\n",
    "    logger.info('finish loading data')\n",
    "\n",
    "    logger.info(f\"creating model '{args.net}'\")\n",
    "    model = get_model(args)\n",
    "\n",
    "    if args.dataset == 'mnist':\n",
    "        flops_input = torch.randn(1, 1, args.input_image_size,\n",
    "                              args.input_image_size)\n",
    "    else:\n",
    "        flops_input = torch.randn(1, 3, args.input_image_size,\n",
    "                              args.input_image_size)\n",
    "    flops, params = profile(model, inputs=(flops_input, ))\n",
    "    flops, params = clever_format([flops, params], \"%.3f\")\n",
    "    logger.info(f\"model: '{args.net}', flops: {flops}, params: {params}\")\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        logger.info(f\"{name},{param.requires_grad}\")\n",
    "\n",
    "    model = model.cuda()\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer, milestones=args.milestones, gamma=args.gamma)\n",
    "    \n",
    "    model = nn.DataParallel(model, device_ids=args.gpus)\n",
    "    \n",
    "    if args.use_prune:\n",
    "        pruner = EagerPruner(model, args.epochs, len(train_loader), \n",
    "                            prune_interval=args.prune_interval,\n",
    "                            prune_num=args.prune_num,\n",
    "                            over_prune_threshold=args.over_prune_threshold,\n",
    "                            prune_fail_times=args.prune_fail_times)\n",
    "        logger.info(\n",
    "                f\"all weights in conv layers {pruner.all_weights_num:d}\")\n",
    "    else:\n",
    "        pruner = None\n",
    "\n",
    "    if args.evaluate:\n",
    "        if not os.path.isfile(args.evaluate):\n",
    "            raise Exception(\n",
    "                f\"{args.resume} is not a file, please check it again\")\n",
    "        logger.info('start only evaluating')\n",
    "        logger.info(f\"start resuming model from {args.evaluate}\")\n",
    "        checkpoint = torch.load(args.evaluate,\n",
    "                                map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        acc1, acc5, throughput = validate(val_loader, model, args)\n",
    "        logger.info(\n",
    "            f\"epoch {checkpoint['epoch']:0>3d}, top1 acc: {acc1:.2f}%, top5 acc: {acc5:.2f}%, throughput: {throughput:.2f}sample/s\"\n",
    "        )\n",
    "\n",
    "        return\n",
    "\n",
    "    start_epoch = 1\n",
    "    # resume training\n",
    "    if os.path.exists(args.resume):\n",
    "        logger.info(f\"start resuming model from {args.resume}\")\n",
    "        checkpoint = torch.load(args.resume, map_location=torch.device('cpu'))\n",
    "        start_epoch += checkpoint['epoch']\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        logger.info(\n",
    "            f\"finish resuming model from {args.resume}, epoch {checkpoint['epoch']}, \"\n",
    "            f\"loss: {checkpoint['loss']:3f}, lr: {checkpoint['lr']:.6f}, \"\n",
    "            f\"top1_acc: {checkpoint['acc1']}%\")\n",
    "\n",
    "    if not os.path.exists(args.checkpoints):\n",
    "        os.makedirs(args.checkpoints)\n",
    "\n",
    "    logger.info('start training')\n",
    "    for epoch in range(start_epoch, args.epochs + 1):\n",
    "        acc1, acc5, losses = train(train_loader, model, criterion, optimizer,\n",
    "                                   scheduler, pruner, epoch, logger, args)\n",
    "        logger.info(\n",
    "            f\"train: epoch {epoch:0>3d}, top1 acc: {acc1:.2f}%, top5 acc: {acc5:.2f}%, losses: {losses:.2f}\"\n",
    "        )\n",
    "\n",
    "        acc1, acc5, throughput = validate(val_loader, model, args)\n",
    "        logger.info(\n",
    "            f\"val: epoch {epoch:0>3d}, top1 acc: {acc1:.2f}%, top5 acc: {acc5:.2f}%, throughput: {throughput:.2f}sample/s\"\n",
    "        )\n",
    "\n",
    "        # remember best prec@1 and save checkpoint\n",
    "        torch.save(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'acc1': acc1,\n",
    "                'loss': losses,\n",
    "                'lr': optimizer.param_groups[0]['lr'],\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "            }, os.path.join(args.checkpoints, 'latest.pth'))\n",
    "        if epoch == args.epochs:\n",
    "            torch.save(\n",
    "                model.module.state_dict(),\n",
    "                os.path.join(\n",
    "                    args.checkpoints,\n",
    "                    \"{}-epoch{}-acc{}.pth\".format(args.network, epoch, acc1)))\n",
    "\n",
    "    training_time = (time.time() - start_time) / 3600\n",
    "    logger.info(\n",
    "        f\"finish training, total training time: {training_time:.2f} hours\")\n",
    "    \n",
    "    if args.use_prune:\n",
    "        overall_rate, layers_rate = pruner.get_prune_rate()        \n",
    "        logger.info(\n",
    "            f\"finish training, total prune rate: {overall_rate:.3f}\")\n",
    "        for i, rate in enumerate(layers_rate):\n",
    "            logger.info(f\"layer {i:0>4d}, rate {rate:.3f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    print(args.__dict__)\n",
    "    get_config_file(args)\n",
    "    print(args.__dict__)\n",
    "    logger = get_logger(__name__, args.log)\n",
    "    main(logger, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar100/cifar-100-python.tar.gz\n",
      "100%|██████████████████████▉| 168198144/169001437 [00:15<00:00, 13245443.43it/s]Extracting ./data/cifar100/cifar-100-python.tar.gz to ./data/cifar100\n",
      "Files already downloaded and verified\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 278, in <module>\n",
      "    sys.exit()\n",
      "NameError: name 'sys' is not defined\n",
      "169009152it [00:18, 8927605.89it/s]                                             \n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
